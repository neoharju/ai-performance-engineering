"""baseline_streams.py - Sequential data transfer and compute (baseline).

Chapter 11: CUDA Streams and Concurrency

This baseline demonstrates sequential execution where each data chunk must:
1. Transfer from host to device (H2D)
2. Compute on the GPU
3. Synchronize before processing the next chunk

The sequential pattern creates bubbles where the GPU compute unit is idle
during memory transfers and vice versa.
"""

from __future__ import annotations

from typing import Optional, List

import torch

from core.harness.benchmark_harness import BaseBenchmark, BenchmarkConfig
from core.benchmark.verification_mixin import VerificationPayloadMixin


class BaselineStreamsBenchmark(VerificationPayloadMixin, BaseBenchmark):
    """Sequential execution - no overlap between H2D transfers and compute."""
    
    def __init__(self):
        super().__init__()
        self.host_data: Optional[List[torch.Tensor]] = None
        self.device_data: Optional[List[torch.Tensor]] = None
        self.results: Optional[List[torch.Tensor]] = None
        self.N = 5_000_000  # Elements per chunk - balanced for H2D/compute overlap
        self.num_chunks = 20  # More chunks to amortize pipeline startup
        # Stream benchmark - fixed dimensions for overlap measurement
        processed = float(self.N * self.num_chunks)
        # Register at init time so pre-run compliance checks pass; setup() may update
        # this if the workload is adjusted before allocation.
        self.register_workload_metadata(
            tokens_per_iteration=processed,
            requests_per_iteration=float(self.num_chunks),
        )
    
    def setup(self) -> None:
        """Setup: Initialize pinned host memory and device buffers."""
        torch.manual_seed(42)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(42)
        
        # Create pinned host memory for async transfers
        self.host_data = [
            torch.randn(self.N, dtype=torch.float32).pin_memory() 
            for _ in range(self.num_chunks)
        ]
        
        # Pre-allocate device buffers
        self.device_data = [
            torch.empty(self.N, dtype=torch.float32, device=self.device)
            for _ in range(self.num_chunks)
        ]
        self.results = [
            torch.empty(self.N, dtype=torch.float32, device=self.device)
            for _ in range(self.num_chunks)
        ]
        
        self._synchronize()
        processed = float(self.N * self.num_chunks)
        self.register_workload_metadata(
            tokens_per_iteration=processed,
            requests_per_iteration=float(self.num_chunks),
        )
    
    def _compute(self, data: torch.Tensor) -> torch.Tensor:
        """Compute-intensive operation on GPU data.
        
        Multiple trig operations to ensure compute time is meaningful
        relative to H2D transfer time for proper overlap demonstration.
        """
        result = data
        for _ in range(3):  # Multiple passes to increase compute time
            result = torch.sin(result) * torch.cos(result) + result * 0.1
            result = torch.tanh(result) + torch.sigmoid(result) * 0.5
        return result
    
    def benchmark_fn(self) -> None:
        """Benchmark: Sequential H2D transfer then compute for each chunk.
        
        Pattern: H2D -> Sync -> Compute -> Sync -> H2D -> Sync -> Compute -> ...
        
        This creates idle time because:
        - GPU compute units are idle during H2D transfers
        - Memory controller is idle during compute
        """
        with self._nvtx_range("baseline_streams_sequential"):
            for i in range(self.num_chunks):
                # Transfer data from host to device (blocking)
                self.device_data[i].copy_(self.host_data[i])
                self._synchronize()  # Wait for transfer to complete
                
                # Compute on device
                self.results[i] = self._compute(self.device_data[i])
                self._synchronize()  # Wait for compute to complete
    
    def teardown(self) -> None:
        """Teardown: Clean up resources."""
        self.host_data = None
        self.device_data = None
        self.results = None
        super().teardown()
    
    def get_config(self) -> BenchmarkConfig:
        """Return benchmark configuration."""
        return BenchmarkConfig(
            iterations=20,
            warmup=10,
            enable_memory_tracking=False,
            enable_profiling=False,
        )

    def get_custom_metrics(self) -> Optional[dict]:
        """Return domain-specific metrics."""
        from core.benchmark.metrics import compute_stream_metrics
        return compute_stream_metrics(
            sequential_time_ms=getattr(self, '_sequential_ms', 10.0),
            overlapped_time_ms=getattr(self, '_overlapped_ms', 5.0),
            num_streams=1,  # Sequential uses default stream only
            num_operations=self.num_chunks * 2,  # transfer + compute per chunk
        )

    def capture_verification_payload(self) -> None:
        if self.host_data is None or self.results is None:
            raise RuntimeError("setup() and benchmark_fn() must be called before capture_verification_payload()")
        sample = self.host_data[0][:256]
        indices = [0, self.num_chunks // 2, self.num_chunks - 1]
        verify_output = torch.cat([self.results[i][:256].detach() for i in indices], dim=0)
        self._set_verification_payload(
            inputs={"host_data": sample},
            output=verify_output,
            batch_size=int(self.num_chunks),
            parameter_count=int(self.N * self.num_chunks),
            precision_flags={
                "fp16": False,
                "bf16": False,
                "fp8": False,
                "tf32": torch.backends.cuda.matmul.allow_tf32 if torch.cuda.is_available() else False,
            },
            output_tolerance=(1e-5, 1e-5),
        )


def get_benchmark() -> BaselineStreamsBenchmark:
    """Factory function for benchmark discovery."""
    return BaselineStreamsBenchmark()


if __name__ == "__main__":
    from core.harness.benchmark_harness import benchmark_main
    benchmark_main(get_benchmark)

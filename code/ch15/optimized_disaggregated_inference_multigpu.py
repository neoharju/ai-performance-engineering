"""Optimized disaggregated inference benchmark (multi-GPU torchrun pipeline).

Chapter 15: Disaggregated Inference (Optimized)

Optimizations:
- Overlap prefill and decode by pipelining KV transfers per request.
- Use non-blocking device transfers in the local verification path.
"""

from __future__ import annotations

import argparse

from ch15.baseline_disaggregated_inference_multigpu import (  # noqa: E402
    DisaggConfig,
    _DisaggregatedInferenceMultiGPUBenchmark,
    _run_torchrun_worker,
)
from core.harness.benchmark_harness import BaseBenchmark  # noqa: E402


class OptimizedDisaggregatedInferenceMultiGPUBenchmark(_DisaggregatedInferenceMultiGPUBenchmark):
    """Pipelined prefill/decode overlap across multi-GPU ranks."""

    def __init__(self) -> None:
        super().__init__(overlap=True, label="optimized_disaggregated_inference_multigpu")


def get_benchmark() -> BaseBenchmark:
    return OptimizedDisaggregatedInferenceMultiGPUBenchmark()


def _parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser()
    parser.add_argument("--iters", type=int, default=4)
    parser.add_argument("--warmup", type=int, default=3)
    return parser.parse_args()


def main() -> None:
    args = _parse_args()
    _run_torchrun_worker(
        DisaggConfig(),
        overlap=True,
        label="optimized_disaggregated_inference_multigpu",
        iters=int(args.iters),
        warmup=int(args.warmup),
    )


if __name__ == "__main__":
    main()

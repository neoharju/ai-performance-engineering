#!/usr/bin/env python3
"""baseline_wide_ep.py - Wide expert-parallel all-to-all (naive pack/unpack) (Ch15).

Pairs with: optimized_wide_ep.py

Design choice (for benchmarkability):
- All experts share the same weights (a single shared expert module).
- Routing/placement changes therefore do NOT change the final output tensor.
- The measured speedup comes from communication (pack/unpack) efficiency, not
  changing the math.

Baseline behavior:
- Simulates expert-parallel all-to-all by packing tokens per destination rank
  using a Python loop + boolean masks.
- Applies the shared expert to the packed buffer, then unpacks back to original
  token order.
"""

from __future__ import annotations

import sys
from pathlib import Path
from typing import Optional

import torch
import torch.nn as nn

repo_root = Path(__file__).parent.parent
if str(repo_root) not in sys.path:
    sys.path.insert(0, str(repo_root))

from ch15.verification_payload_mixin import VerificationPayloadMixin
from core.harness.benchmark_harness import BaseBenchmark, BenchmarkConfig, WorkloadMetadata
from core.optimization.moe_inference import ExpertMLP


def _pseudo_uniform_expert_ids(token_ids: torch.Tensor, num_experts: int) -> torch.Tensor:
    if token_ids.dtype != torch.int64:
        token_ids = token_ids.to(torch.int64)
    return ((token_ids * 1103515245 + 12345) % int(num_experts)).to(torch.int64)


class BaselineWideEPBenchmark(VerificationPayloadMixin, BaseBenchmark):
    """Baseline: naive per-rank pack/unpack for expert-parallel all-to-all."""

    def __init__(self) -> None:
        super().__init__()
        self.hidden_size = 1024
        self.ffn_size = 4096
        self.world_size = 64
        self.experts_per_rank = 1
        self.num_experts = self.world_size * self.experts_per_rank
        self.batch = 128
        self.seq = 32
        self.dtype = torch.bfloat16

        tokens = self.batch * self.seq
        self._workload = WorkloadMetadata(
            requests_per_iteration=float(self.batch),
            tokens_per_iteration=float(tokens),
        )
        self.register_workload_metadata(
            requests_per_iteration=float(self.batch),
            tokens_per_iteration=float(tokens),
        )

        self.expert: Optional[nn.Module] = None
        self.inputs: Optional[torch.Tensor] = None
        self.expert_ids: Optional[torch.Tensor] = None
        self.output: Optional[torch.Tensor] = None
        self._verify_probe: Optional[torch.Tensor] = None
        self._verify_meta: Optional[torch.Tensor] = None

    def setup(self) -> None:
        if not torch.cuda.is_available():
            raise RuntimeError("SKIPPED: CUDA required for wide-EP benchmark")

        if self.num_experts <= 0:
            raise ValueError("num_experts must be positive")
        if self.experts_per_rank <= 0:
            raise ValueError("experts_per_rank must be positive")
        if self.num_experts % self.world_size != 0:
            raise ValueError("num_experts must be divisible by world_size")

        torch.manual_seed(42)
        torch.cuda.manual_seed_all(42)

        self.expert = ExpertMLP(self.hidden_size, self.ffn_size, device=self.device, dtype=self.dtype).eval()
        self.inputs = torch.randn(self.batch, self.seq, self.hidden_size, device=self.device, dtype=self.dtype)

        token_ids = torch.arange(self.batch * self.seq, device=self.device, dtype=torch.int64)
        self.expert_ids = _pseudo_uniform_expert_ids(token_ids, self.num_experts).view(self.batch, self.seq)

        self._verify_probe = self.inputs[:1, :1, :256].detach().cpu()
        self._verify_meta = torch.tensor(
            [int(self.world_size), int(self.experts_per_rank), int(self.num_experts)],
            dtype=torch.int64,
        )

        for _ in range(3):
            with torch.no_grad():
                _ = self.expert(self.inputs.view(-1, self.hidden_size))

    def benchmark_fn(self) -> None:
        if self.expert is None or self.inputs is None or self.expert_ids is None:
            raise RuntimeError("setup() must run before benchmark_fn()")

        flat = self.inputs.view(-1, self.hidden_size)
        expert_ids_flat = self.expert_ids.reshape(-1)
        dest_ranks = torch.div(expert_ids_flat, self.experts_per_rank, rounding_mode="floor")

        with self._nvtx_range("baseline_wide_ep"):
            with torch.no_grad():
                send_tokens: list[torch.Tensor] = []
                send_pos: list[torch.Tensor] = []
                for r in range(self.world_size):
                    mask = dest_ranks == r
                    indices = mask.nonzero(as_tuple=False).squeeze(-1)
                    if indices.numel() == 0:
                        continue
                    send_tokens.append(flat.index_select(0, indices))
                    send_pos.append(indices)
                if not send_tokens:
                    raise RuntimeError("Routing produced no tokens for any rank")

                perm = torch.cat(send_pos, dim=0)
                send_buf = torch.cat(send_tokens, dim=0)

                recv_buf = torch.empty_like(send_buf)
                recv_buf.copy_(send_buf)

                recv_out = self.expert(recv_buf)

                recv_back = torch.empty_like(recv_out)
                recv_back.copy_(recv_out)

                out_flat = torch.empty_like(flat)
                out_flat.index_copy_(0, perm, recv_back)
                self.output = out_flat.view(self.batch, self.seq, self.hidden_size)


    def capture_verification_payload(self) -> None:
        if self.output is None or self._verify_probe is None or self._verify_meta is None:
            raise RuntimeError("setup() and benchmark_fn() must run before capture_verification_payload()")
        output_slice = self.output[:2, :2, :256].detach().cpu().float().clone()
        param_count = sum(p.numel() for p in self.expert.parameters()) if self.expert is not None else 0
        self._set_verification_payload(
            inputs={"probe": self._verify_probe, "routing": self._verify_meta},
            output=output_slice,
            batch_size=int(self.batch),
            parameter_count=int(param_count),
            precision_flags={
                "fp16": False,
                "bf16": True,
                "fp8": False,
                "tf32": torch.backends.cuda.matmul.allow_tf32 if torch.cuda.is_available() else False,
            },
            output_tolerance=(0.0, 0.0),
            signature_overrides={
                "world_size": int(self.world_size),
                "collective_type": "all_to_all",
            },
        )

    def teardown(self) -> None:
        self.expert = None
        self.inputs = None
        self.expert_ids = None
        self.output = None
        super().teardown()

    def get_config(self) -> BenchmarkConfig:
        return BenchmarkConfig(iterations=20, warmup=10)

    def get_workload_metadata(self) -> Optional[WorkloadMetadata]:
        return self._workload

    def validate_result(self) -> Optional[str]:
        if self.output is None:
            return "Output not produced"
        return None


def get_benchmark() -> BaseBenchmark:
    return BaselineWideEPBenchmark()


if __name__ == "__main__":
    from core.harness.benchmark_harness import benchmark_main

    benchmark_main(get_benchmark)